{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cinnamon AI Bootcamp\n",
    "`Name:` Nguyen Truong Phat\n",
    "\n",
    "## Generating hand-written digits using Kernel Density Estimator\n",
    "\n",
    "### Kernel Density Estimation\n",
    "Kernel Density Estimation is a non-parametric method for estimating the probability of a given point, using a dataset.\n",
    "\n",
    "#### Univariate Gaussian kernel\n",
    "\n",
    "Given a point $x$, its probability respected to a dataset $x_1,x_2,x_3,x_4..,x_n$ is:\n",
    "$$\n",
    "\\hat{f_h}(x)= \\frac{1}{nh}\\sum_{i=1}^NK  \\left( \\frac{x-x_i}{h} \\right)\n",
    "$$\n",
    "where $K$ is a kernel function.\n",
    "\n",
    "A kernel function is **typically**:\n",
    "- non-negative: $K(x) > 0, \\forall x$\n",
    "- symmetric: $K(x) = K(-x), \\forall x$\n",
    "- decreasing: $K'(x) \\leq 0, \\forall x>0$\n",
    "\n",
    "There are variety of kernels: Gaussian, Triangle, Uniform, etc. However, the choice of kernel is not that important no matter what kernel you choose. As you get more and more data, the estimations will end up being very similar [1].In contrast the choice of bandwidth is very crucial. If larger $h$ is, the more it spreads the kernel. \n",
    "\n",
    "#### \"Extended\" Univariate Gaussian kernel\n",
    "A simple way to extend univariate gaussian kernel to work with higher dimension is to introduce $p-norm$ to calculate distance (Let's call this **\"Extended\" Univariate Gaussian kernel**):\n",
    "\n",
    "$$\n",
    "\\hat{f_h}(x)=\\frac{1}{nh} \\sum_{i=1}^NK \\left( \\frac{||x-x_i||_p}{h} \\right) \n",
    "$$\n",
    "\n",
    "The choice of $p$ can be varied for different problems. Usually, the norm of $p=1$,$p=2$ or $p=+\\infty$ are common. A good start would be L2 distance, which is invariant to rotation. \n",
    "\n",
    "The choice of h could depends on users' preference. For the sake of evaluating an choosen $h$, I come up with this method. Let's call it LMSE  (Least mean squared error). The objective of this method is to choose $h$ in order to make the mean of probability of every instances in a class equals to the proportion of samples of that class in the data. \n",
    "\n",
    "$$\n",
    "h = \\underset{h}{argmin} \\left( \\frac{\\sum_{i=1}^N \\hat{f_h}(x_i)}{N} -\\frac{1}{N_C} \\right)^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This formula assumes that number of each class are equally distributed.\n",
    "\n",
    "**Proof**:\n",
    "$$\n",
    "\\text{We want } \\frac{\\sum_{c \\in C}\\frac{\\sum_{x\\in c} \\hat{f}_h(x)}{n_c}}{N_C} = \\frac{1}{N_C}\\\\\n",
    "\\Rightarrow \\sum_{c \\in C}\\frac{\\sum_{x\\in c} \\hat{f}_h(x)}{n_c} = 1\\\\\n",
    "\\text{Since } n_c \\text { is equal } \\forall c \\in C, n_C = \\frac{N}{N_C} \\forall c \\in C \\\\\n",
    "\\Rightarrow \\sum_{c \\in C}\\frac{\\sum_{x\\in c} \\hat{f}_h(x)}{\\frac{N}{N_C}} = 1\\\\\n",
    "\\Rightarrow \\frac{\\sum_{x \\in X} \\hat{f_h}(x)}{N} - \\frac{1}{N_C} = 0\n",
    "$$\n",
    "In which:\n",
    "- $c$: c-th class \n",
    "- $C$: a set of classes\n",
    "- $N_C$: number of classes\n",
    "- $n_c$: number of instances belongs to c-th class\n",
    "- $N$: number of data points in the dataset\n",
    "- $X$: a set of data points \n",
    "\n",
    "Therefore, we can develop a least square problem. \n",
    "\n",
    "#### Multivariate Gaussian kernel\n",
    "The problem of p-norm Gaussian kernel is, without a doubt: the bandwidth $p$ value should be treated seperately for each feature of the vector since they're coming from different distribution and have different scales. Thus, the kernel density estimate [2] can be defined to be:\n",
    "$$\n",
    "\\hat{f_H}(x)=\\frac{1}{n} \\sum_{i=1}^N K_H(x-x_i)\n",
    "$$\n",
    "- H is the $d\\times d$ bandwidth matrix which is symmetric and positive definite\n",
    "- since the choice of kernel is not important, we use the well-known multivariate normal kernel:  \n",
    "$$K_H(x) =  (2\\pi)^{-d/2}|H|^{-1/2}e^{\\frac{-1}{2}x^T H^{-1} x}$$\n",
    "\n",
    "\n",
    "\n",
    "### Estimating bandwidth H for KDE for with Multivariate Gaussian Kernel\n",
    "2 simple way to estimate $H$ is to use Silverman's rule and Scott rule.\n",
    "These 2 method are assumming the data to come from gaussian distribution. \n",
    "\n",
    "#### Silverman's rule of thumbs\n",
    "[3] Silverman's rule of thumbs suggest using $\\sqrt{H_{ii}}=(\\frac{4}{d+2})^\\frac{1}{d+4}n^{\\frac{-1}{d+4}}\\sigma_i$ where $\\sigma_i$ is the standard deviation of the i-th variable and $H_{ij}=0, \\forall i\\neq j$\n",
    "\n",
    "#### Scotts' rule\n",
    "[3] Scott's rule is $\\sqrt{H_{ii}} = n^{\\frac{-1}{d+4}}\\sigma_i$ where $\\sigma_i$ is the standard deviation of the i-th variable and $H_{ij}=0, \\forall i\\neq j$\n",
    "\n",
    "The problem arises when the assumptions aren't met\n",
    "\n",
    "## References\n",
    "\n",
    "[1] [webel od - Intro to Kernel Density Estimation](https://www.youtube.com/watch?v=x5zLaWT5KPs)<br>\n",
    "[2] [Wiki - Kernel density estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation)<br>\n",
    "[3] [Wiki - Multivariate kernel density estimation](https://en.wikipedia.org/wiki/Multivariate_kernel_density_estimation)<br>\n",
    "[4] [Nicolas Langrené∗, Xavier Warin - Fast and stable multivariate kernel densityestimation by fast sum updating](https://arxiv.org/pdf/1712.00993.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from numpy.linalg import norm as L2\n",
    "from scipy.stats import norm as univariate_normal\n",
    "from scipy.stats import multivariate_normal\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 60000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.transpose((1,2,0)).reshape(28*28,60000).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelDensityEstimator:\n",
    "    def __init__(self,kernel=\"multivariate_gaussian\", bandwidth_estimator = \"silverman\",univariate_bandwidth = None):\n",
    "        \n",
    "        kernels = {\"multivariate_gaussian\":self.kernel_multivariate_gaussian,\n",
    "                   \"univariate_gaussian\": self.kernel_univariate_gaussian}\n",
    "        bandwidth_estimators = {\"silverman\":self.est_bandwidth_silverman,\n",
    "                               \"scott\":self.est_bandwidth_scott}\n",
    "        compatible_estimators = {\"multivariate_gaussian\":[\"silverman\",\"scott\"],\n",
    "                               \"univariate\":[]}\n",
    "                    \n",
    "            \n",
    "        self.kernel =  kernels[kernel]\n",
    "\n",
    "        # if multivariate gaussian kernel is chosen, choose an estimator\n",
    "        if kernel==\"multivariate_gaussian\":\n",
    "            self.bandwidth_estimator = bandwidth_estimators[bandwidth_estimator]\n",
    "        \n",
    "        # if choosing univariate kernel without bandwidth clarified, print out a warning\n",
    "        elif kernel==\"univariate_gaussian\" and (not univariate_bandwidth):\n",
    "            print(\"Please define your \\\"univariate_bandwidth\\\" parameters since the bandwidth cannot \\\n",
    "                    automatically estimated using univariate kernel yet\")\n",
    "        \n",
    "        else:\n",
    "            self.univariate_bandwidth = univariate_bandwidth\n",
    "                    \n",
    "        # Kernel choice\n",
    "        self.kernel = kernels[kernel]\n",
    "        \n",
    "        # Store data\n",
    "        self.data = None\n",
    "        \n",
    "    def kernel_multivariate_gaussian(self,x):\n",
    "        # Retrieve data\n",
    "        data = self.data\n",
    "        \n",
    "        # Get dim of data\n",
    "        d = data.shape[1]\n",
    "        \n",
    "        # Estimate bandwidth\n",
    "        H = self.bandwidth_estimator()\n",
    "        \n",
    "        # Multivariate normal density estimate of x\n",
    "        var = multivariate_normal(mean=np.zeros(d), cov=H,allow_singular=True)\n",
    "        density = np.expand_dims(var.pdf(x),1)\n",
    "        print(density)\n",
    "        return density\n",
    "    \n",
    "    def kernel_univariate_gaussian(self,x):\n",
    "        # Retrieve data\n",
    "        data = self.data\n",
    "        \n",
    "        # Get dim of data\n",
    "        d = data.shape[1]\n",
    "        \n",
    "        # Estimate bandwidth\n",
    "        h = self.univariate_bandwidth\n",
    "        \n",
    "        # Calculate density\n",
    "        density = univariate_normal.pdf(x)/h\n",
    "        \n",
    "        return density\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        \n",
    "        self.data = X # Make a pointer to the data variable\n",
    "        \n",
    "        # If using univariate kernel then print MSE if y declared\n",
    "        if self.kernel == self.kernel_univariate_gaussian:\n",
    "            print(\"Mean Square Error: \",self.MSE(X,y))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def MSE(self,X,y):\n",
    "        \n",
    "        num_classes = len(np.unique(y))\n",
    "        N = len(X)\n",
    "        proba = self.predict_proba(X)\n",
    "        MSE = (proba.mean() - 1/num_classes)**2\n",
    "        return MSE \n",
    "    \n",
    "    def est_bandwidth_scott(self):\n",
    "        # Retrieve data\n",
    "        data = self.data\n",
    "        \n",
    "        # Get number of samples\n",
    "        n = data.shape[0]\n",
    "        \n",
    "        # Get dim of data\n",
    "        d = data.shape[1]\n",
    "        \n",
    "        # Compute standard along each i-th variable\n",
    "        std = np.std(data,axis=0)\n",
    "        \n",
    "        # Construct the H diagonal bandwidth matrix with std along the diag\n",
    "        H = (n**(-1/(d+4))*np.diag(std))**2\n",
    "        \n",
    "        return H\n",
    "    \n",
    "    def est_bandwidth_silverman(self):\n",
    "        # Retrieve data\n",
    "        data = self.data\n",
    "        \n",
    "        # Get number of samples\n",
    "        n = data.shape[0]\n",
    "        \n",
    "        # Get dim of data\n",
    "        d = data.shape[1]\n",
    "        \n",
    "        # Compute standard along each i-th variable\n",
    "        std = np.std(data,axis=0)\n",
    "        \n",
    "        # Construct the H diagonal bandwidth matrix with std along the diag\n",
    "        H = (4/(d+2))**(1/(d+4))*(n**(-1/(d+4)))*np.diag(std)\n",
    "        return H\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        \n",
    "        kernel_func = self.kernel\n",
    "\n",
    "        # Retrieve data\n",
    "        data = self.data\n",
    "        \n",
    "        # Retrieve number of samples\n",
    "        n = data.shape[0]\n",
    "\n",
    "        # Init the estimated probabilities list\n",
    "        est_probs = []\n",
    "        \n",
    "        for item in tqdm_notebook(X):\n",
    "            est_prob = 1/n*np.sum(kernel_func(data-item))\n",
    "            est_probs.append(est_prob)\n",
    "            \n",
    "        return np.array(est_probs)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        # if x is a vector (has 1 axis)\n",
    "        if len(X.shape) == 1:\n",
    "            # expand one more axis to represent a matrix\n",
    "            X = np.expand_dims(X,0)\n",
    "            \n",
    "        proba = self.predict_proba(X)\n",
    "                        \n",
    "        return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Univariate Gaussian Kernel\n",
    "DON'T RUN! ITS VERY SLOW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Estimator = KernelDensityEstimator(kernel=\"univariate_gaussian\",univariate_bandwidth=1).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is extremely slow since this method doesn't scale well with the amount of data nor dimensions of data. However, it works decently fast when being used on small-sized and low dimensional data. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4160b490cf954c33b81de94429081803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1831), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Square Error:  2.8536841657419042e-06\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "data = loadmat('cardio.mat')\n",
    "X = data['X']\n",
    "Y = data['y'][:,0]\n",
    "\n",
    "# Choice of bandwith (h=11 is kinda tuned)\n",
    "bandwidth = 11 \n",
    "Estimator = KernelDensityEstimator(kernel=\"univariate_gaussian\",univariate_bandwidth=bandwidth).fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bad practice here is that 2 classes are not balanced. However, we could see how Extended Univariate Kernel could be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Gaussian Kernel\n",
    "#### Silverman's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab37069ebb342cb83bb73d5a2fe0073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Estimator = KernelDensityEstimator(kernel=\"multivariate_gaussian\", bandwidth_estimator=\"silverman\")\n",
    "Estimator.fit(x_train,y_train)\n",
    "Estimator.predict(x_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scott's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e08f3598bc4bca87afd6e03c3de378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Estimator = KernelDensityEstimator(kernel=\"multivariate_gaussian\", bandwidth_estimator=\"scott\")\n",
    "Estimator.fit(x_train,y_train)\n",
    "Estimator.predict(x_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f07c0747310>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOYElEQVR4nO3dbYxc5XnG8euKbUwxJvHGseMQFxzjFAg0Jl0ZkBFQoVCCIgGKCLGiiFBapwlOQutKUFoVWtHKrRIiSimSKS6m4iWQgPAHmsSyECRqcFmoAROHN+MS4+0aswIDIfZ6fffDjqsFdp5dZs68eO//T1rNzLnnzLk1cPmcmeeceRwRAjD5faDTDQBoD8IOJEHYgSQIO5AEYQeSmNrOjR3i6XGoZrRzk0Aqv9Fb2ht7PFatqbDbPkfS9ZKmSPrXiFhVev6hmqGTfVYzmwRQsDE21K01fBhve4qkGyV9TtLxkpbZPr7R1wPQWs18Zl8i6fmI2BoReyXdJem8atoCULVmwn6kpF+Nery9tuwdbC+33We7b0h7mtgcgGY0E/axvgR4z7m3EbE6InojoneapjexOQDNaCbs2yXNH/X445J2NNcOgFZpJuyPSlpke4HtQyR9SdK6atoCULWGh94iYp/tFZJ+rJGhtzUR8XRlnQGoVFPj7BHxgKQHKuoFQAtxuiyQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJNDWLK7qfp5b/E0/5yOyWbv+ZPz+6bm34sP3FdY9auLNYP+wbLtb/97pD6tYe7/1+cd1dw28V6yffs7JYP+bPHinWO6GpsNveJukNScOS9kVEbxVNAaheFXv234+IXRW8DoAW4jM7kESzYQ9JP7H9mO3lYz3B9nLbfbb7hrSnyc0BaFSzh/FLI2KH7TmS1tv+ZUQ8PPoJEbFa0mpJOsI90eT2ADSoqT17ROyo3e6UdJ+kJVU0BaB6DYfd9gzbMw/cl3S2pM1VNQagWs0cxs+VdJ/tA69zR0T8qJKuJpkpxy0q1mP6tGJ9xxkfKtbfPqX+mHDPB8vjxT/9dHm8uZP+49czi/V/+OdzivWNJ95Rt/bi0NvFdVcNfLZY/9hPD75PpA2HPSK2Svp0hb0AaCGG3oAkCDuQBGEHkiDsQBKEHUiCS1wrMHzmZ4r16269sVj/5LT6l2JOZkMxXKz/9Q1fLdanvlUe/jr1nhV1azNf3ldcd/qu8tDcYX0bi/VuxJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0C05/ZUaw/9pv5xfonpw1U2U6lVvafUqxvfbP8U9S3LvxB3drr+8vj5HP/6T+L9VY6+C5gHR97diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhHtG1E8wj1xss9q2/a6xeAlpxbru88p/9zzlCcPL9af+MYN77unA67d9bvF+qNnlMfRh197vViPU+v/APG2bxVX1YJlT5SfgPfYGBu0OwbHnMuaPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4exeYMvvDxfrwq4PF+ot31B8rf/r0NcV1l/z9N4v1OTd27ppyvH9NjbPbXmN7p+3No5b12F5v+7na7awqGwZQvYkcxt8q6d2z3l8paUNELJK0ofYYQBcbN+wR8bCkdx9Hnidpbe3+WknnV9wXgIo1+gXd3Ijol6Ta7Zx6T7S93Haf7b4h7WlwcwCa1fJv4yNidUT0RkTvNE1v9eYA1NFo2Adsz5Ok2u3O6loC0AqNhn2dpItr9y+WdH817QBolXF/N972nZLOlDTb9nZJV0taJelu25dKeknSha1scrIb3vVqU+sP7W58fvdPffkXxforN00pv8D+8hzr6B7jhj0iltUpcXYMcBDhdFkgCcIOJEHYgSQIO5AEYQeSYMrmSeC4K56tW7vkxPKgyb8dtaFYP+PCy4r1md9/pFhH92DPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+CZSmTX7168cV131p3dvF+pXX3las/8UXLyjW478/WLc2/+9+XlxXbfyZ8wzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEkzZnNzgH55arN9+9XeK9QVTD21425+6bUWxvujm/mJ939ZtDW97smpqymYAkwNhB5Ig7EAShB1IgrADSRB2IAnCDiTBODuKYuniYv2IVduL9Ts/8eOGt33sg39UrP/O39S/jl+Shp/b2vC2D1ZNjbPbXmN7p+3No5ZdY/tl25tqf+dW2TCA6k3kMP5WSeeMsfx7EbG49vdAtW0BqNq4YY+IhyUNtqEXAC3UzBd0K2w/WTvMn1XvSbaX2+6z3TekPU1sDkAzGg37TZIWSlosqV/Sd+s9MSJWR0RvRPRO0/QGNwegWQ2FPSIGImI4IvZLulnSkmrbAlC1hsJue96ohxdI2lzvuQC6w7jj7LbvlHSmpNmSBiRdXXu8WFJI2ibpaxFRvvhYjLNPRlPmzinWd1x0TN3axiuuL677gXH2RV9+8exi/fXTXi3WJ6PSOPu4k0RExLIxFt/SdFcA2orTZYEkCDuQBGEHkiDsQBKEHUiCS1zRMXdvL0/ZfJgPKdZ/HXuL9c9/8/L6r33fxuK6Byt+ShoAYQeyIOxAEoQdSIKwA0kQdiAJwg4kMe5Vb8ht/2nln5J+4cLylM0nLN5WtzbeOPp4bhg8qVg/7P6+pl5/smHPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+ybn3hGL92W+Vx7pvXrq2WD/90PI15c3YE0PF+iODC8ovsH/cXzdPhT07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPtBYOqCo4r1Fy75WN3aNRfdVVz3C4fvaqinKlw10FusP3T9KcX6rLXl353HO427Z7c93/aDtrfYftr2t2vLe2yvt/1c7XZW69sF0KiJHMbvk7QyIo6TdIqky2wfL+lKSRsiYpGkDbXHALrUuGGPiP6IeLx2/w1JWyQdKek8SQfOpVwr6fxWNQmgee/rCzrbR0s6SdJGSXMjol8a+QdB0pw66yy33We7b0h7musWQMMmHHbbh0v6oaTLI2L3RNeLiNUR0RsRvdM0vZEeAVRgQmG3PU0jQb89Iu6tLR6wPa9WnydpZ2taBFCFcYfebFvSLZK2RMR1o0rrJF0saVXt9v6WdDgJTD36t4v1139vXrF+0d/+qFj/kw/dW6y30sr+8vDYz/+l/vBaz63/VVx31n6G1qo0kXH2pZK+Iukp25tqy67SSMjvtn2ppJckXdiaFgFUYdywR8TPJI05ubuks6ptB0CrcLoskARhB5Ig7EAShB1IgrADSXCJ6wRNnffRurXBNTOK6359wUPF+rKZAw31VIUVL59WrD9+U3nK5tk/2Fys97zBWHm3YM8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mkGWff+wflny3e+6eDxfpVxzxQt3b2b73VUE9VGRh+u27t9HUri+se+1e/LNZ7XiuPk+8vVtFN2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJpxtm3nV/+d+3ZE+9p2bZvfG1hsX79Q2cX6x6u9+O+I4699sW6tUUDG4vrDhermEzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEo6I8hPs+ZJuk/RRjVy+vDoirrd9jaQ/lvRK7alXRUT9i74lHeGeONlM/Aq0ysbYoN0xOOaJGRM5qWafpJUR8bjtmZIes72+VvteRHynqkYBtM5E5mfvl9Rfu/+G7S2Sjmx1YwCq9b4+s9s+WtJJkg6cg7nC9pO219ieVWed5bb7bPcNaU9TzQJo3ITDbvtwST+UdHlE7JZ0k6SFkhZrZM//3bHWi4jVEdEbEb3TNL2ClgE0YkJhtz1NI0G/PSLulaSIGIiI4YjYL+lmSUta1yaAZo0bdtuWdIukLRFx3ajl80Y97QJJ5ek8AXTURL6NXyrpK5Kesr2ptuwqSctsL5YUkrZJ+lpLOgRQiYl8G/8zSWON2xXH1AF0F86gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJDHuT0lXujH7FUn/M2rRbEm72tbA+9OtvXVrXxK9NarK3o6KiI+MVWhr2N+zcbsvIno71kBBt/bWrX1J9NaodvXGYTyQBGEHkuh02Fd3ePsl3dpbt/Yl0Vuj2tJbRz+zA2ifTu/ZAbQJYQeS6EjYbZ9j+xnbz9u+shM91GN7m+2nbG+y3dfhXtbY3ml786hlPbbX236udjvmHHsd6u0a2y/X3rtNts/tUG/zbT9oe4vtp21/u7a8o+9doa+2vG9t/8xue4qkZyV9VtJ2SY9KWhYRv2hrI3XY3iapNyI6fgKG7dMlvSnptog4obbsHyUNRsSq2j+UsyLiii7p7RpJb3Z6Gu/abEXzRk8zLul8SV9VB9+7Ql9fVBvet07s2ZdIej4itkbEXkl3STqvA310vYh4WNLguxafJ2lt7f5ajfzP0nZ1eusKEdEfEY/X7r8h6cA04x197wp9tUUnwn6kpF+Nerxd3TXfe0j6ie3HbC/vdDNjmBsR/dLI/zyS5nS4n3cbdxrvdnrXNONd8941Mv15szoR9rGmkuqm8b+lEfEZSZ+TdFntcBUTM6FpvNtljGnGu0Kj0583qxNh3y5p/qjHH5e0owN9jCkidtRud0q6T903FfXAgRl0a7c7O9zP/+umabzHmmZcXfDedXL6806E/VFJi2wvsH2IpC9JWteBPt7D9ozaFyeyPUPS2eq+qajXSbq4dv9iSfd3sJd36JZpvOtNM64Ov3cdn/48Itr+J+lcjXwj/4Kkv+xED3X6+oSkJ2p/T3e6N0l3auSwbkgjR0SXSvqwpA2Snqvd9nRRb/8u6SlJT2okWPM61NtpGvlo+KSkTbW/czv93hX6asv7xumyQBKcQQckQdiBJAg7kARhB5Ig7EAShB1IgrADSfwfs4RxaLJFjqkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(x_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
